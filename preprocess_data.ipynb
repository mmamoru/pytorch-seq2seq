{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import emoji\n",
    "import pickle\n",
    "import os\n",
    "group_len=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_self_reply_pairs(twitter_data):\n",
    "    dialogue_tweets = []\n",
    "    for i in range(1,len(twitter_data),3):\n",
    "        if re.match('@',twitter_data[i])!=None:\n",
    "            dialogue_tweets.append(twitter_data[i-1])\n",
    "            dialogue_tweets.append(twitter_data[i])\n",
    "            dialogue_tweets.append(twitter_data[i+1])\n",
    "    return dialogue_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_hashtag_tweets_groups(twitter_data):\n",
    "    hashtag = r'[#＃]([\\w一-龠ぁ-んァ-ヴーａ-ｚ]+( |　))'\n",
    "    dialogue_tweets = []\n",
    "    for i in range(0,len(twitter_data),3):\n",
    "        if re.search(hashtag,twitter_data[i])==None and re.search(hashtag,twitter_data[i+1])==None and re.search(hashtag,twitter_data[i+2])==None:\n",
    "            dialogue_tweets.append(twitter_data[i])\n",
    "            dialogue_tweets.append(twitter_data[i+1])\n",
    "            dialogue_tweets.append(twitter_data[i+2])\n",
    "        else:\n",
    "            pass\n",
    "    return dialogue_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_hashtag_eos(twitter_data):\n",
    "    hashtag = r'[#＃]([\\w一-龠ぁ-んァ-ヴーａ-ｚ]+$)'\n",
    "    dialogue_tweets = []\n",
    "    for ele in twitter_data:\n",
    "        ele_hashtag_deleted = re.sub(hashtag,'',ele)\n",
    "        dialogue_tweets.append(ele_hashtag_deleted)\n",
    "    return dialogue_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_url(twitter_data):\n",
    "    url = r'(https?|ftp)(:\\/\\/[-_\\.!~*\\'()a-zA-Z0-9;\\/?:\\@&=\\+\\$,%#]+)'\n",
    "    dialogue_tweets = []\n",
    "    for ele in twitter_data:\n",
    "        ele_url_deleted = re.sub(url,'',ele)\n",
    "        dialogue_tweets.append(ele_url_deleted)\n",
    "    return dialogue_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_username_sos(twitter_data):\n",
    "    username = r'@([a-zA-Z0-9_…]+ )'\n",
    "    dialogue_tweets = []\n",
    "    for ele in twitter_data:\n",
    "        ele_username_deleted = re.sub(username,'',ele)\n",
    "        dialogue_tweets.append(ele_username_deleted)\n",
    "    return dialogue_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_inline_username(twitter_data):\n",
    "    username = r'@([a-zA-Z0-9_…]+)'\n",
    "    dialogue_tweets = []\n",
    "    for ele in twitter_data:\n",
    "        ele_username_deleted = re.sub(username,'',ele)\n",
    "        dialogue_tweets.append(ele_username_deleted)\n",
    "    return dialogue_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_emoji(twitter_data):\n",
    "    dialogue_tweets = []\n",
    "    for ele in twitter_data:\n",
    "        ele_emoji_deleted = ''.join(char for char in ele if char not in emoji.UNICODE_EMOJI)\n",
    "        dialogue_tweets.append(ele_emoji_deleted)\n",
    "    return dialogue_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_brackets(twitter_data):\n",
    "    brackets = []\n",
    "    brackets.append(r'【(.+)】')\n",
    "    brackets.append(r'《(.+)》')\n",
    "    brackets.append(r'\\((.+)\\)')\n",
    "    brackets.append(r'（(.+)）')\n",
    "    dialogue_tweets = []\n",
    "    for ele in twitter_data:\n",
    "        for bracket in brackets:\n",
    "            ele = re.sub(bracket,'',ele)\n",
    "        dialogue_tweets.append(ele)\n",
    "    return dialogue_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_blank(twitter_data):\n",
    "    space = r'\\s+'\n",
    "    dialogue_tweets = []\n",
    "    for i in range(0,len(twitter_data),3):\n",
    "        if twitter_data[i]=='' or twitter_data[i+1]=='' or twitter_data[i+2]=='':\n",
    "            pass\n",
    "        elif re.match(space,twitter_data[i])!=None or re.match(space,twitter_data[i+1])!=None or re.match(space,twitter_data[i+2])!=None:\n",
    "            pass\n",
    "        else:\n",
    "            dialogue_tweets.append(twitter_data[i])\n",
    "            dialogue_tweets.append(twitter_data[i+1])\n",
    "            dialogue_tweets.append(twitter_data[i+2])\n",
    "    return dialogue_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_line_feed_code(twitter_data):\n",
    "    dialogue_tweets = []\n",
    "    for ele in twitter_data:\n",
    "        ele_code_deleted = re.sub('\\n','',ele)\n",
    "        dialogue_tweets.append(ele_code_deleted)\n",
    "    return dialogue_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_same_char_sequence(twitter_data):\n",
    "    dialogue_tweets = []\n",
    "    for ele in twitter_data:\n",
    "        deleted_ele = re.sub(r'あ{2,}','あ',ele)\n",
    "        deleted_ele = re.sub(r'い{3,}','い',deleted_ele)\n",
    "        deleted_ele = re.sub(r'う{2,}','う',deleted_ele)\n",
    "        deleted_ele = re.sub(r'え{3,}','え',deleted_ele)\n",
    "        deleted_ele = re.sub(r'お{2,}','お',deleted_ele)\n",
    "        deleted_ele = re.sub(r'ア{2,}','あ',deleted_ele)\n",
    "        deleted_ele = re.sub(r'イ{3,}','い',deleted_ele)\n",
    "        deleted_ele = re.sub(r'ウ{2,}','う',deleted_ele)\n",
    "        deleted_ele = re.sub(r'エ{3,}','え',deleted_ele)\n",
    "        deleted_ele = re.sub(r'オ{2,}','お',deleted_ele)\n",
    "        deleted_ele = re.sub(r'ぁ{2,}','ぁ',deleted_ele)\n",
    "        deleted_ele = re.sub(r'ぃ{2,}','ぃ',deleted_ele)\n",
    "        deleted_ele = re.sub(r'ぅ{2,}','ぅ',deleted_ele)\n",
    "        deleted_ele = re.sub(r'ぇ{2,}','ぇ',deleted_ele)\n",
    "        deleted_ele = re.sub(r'ぉ{2,}','ぉ',deleted_ele)\n",
    "        deleted_ele = re.sub(r'ァ{2,}','ぁ',deleted_ele)\n",
    "        deleted_ele = re.sub(r'ィ{2,}','ぃ',deleted_ele)\n",
    "        deleted_ele = re.sub(r'ゥ{2,}','ぅ',deleted_ele)\n",
    "        deleted_ele = re.sub(r'ェ{2,}','ぇ',deleted_ele)\n",
    "        deleted_ele = re.sub(r'ォ{2,}','ぉ',deleted_ele)\n",
    "        deleted_ele = re.sub(r'w{2,}','w',deleted_ele.lower())\n",
    "        deleted_ele = re.sub(r'ｗ{2,}','w',deleted_ele)\n",
    "        deleted_ele = re.sub(r'[…\\,\\.]','',deleted_ele)\n",
    "        deleted_ele = re.sub(r'!{2,}','!',deleted_ele)\n",
    "        deleted_ele = re.sub(r'！{2,}','!',deleted_ele)\n",
    "        deleted_ele = re.sub(r'笑{2,}','笑',deleted_ele)\n",
    "        dialogue_tweets.append(deleted_ele)\n",
    "    return dialogue_tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neologdn\n",
    "\n",
    "def neolog_normalize(twitter_data):\n",
    "    dialogue_tweets = []\n",
    "    for ele in twitter_data:\n",
    "        normalized_ele = neologdn.normalize(ele)\n",
    "        dialogue_tweets.append(normalized_ele)\n",
    "    return dialogue_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(twitter_data,save=False,save_name='twitter_preprocessed.pickle'):    \n",
    "    try:\n",
    "        twitter_data_ = delete_self_reply_pairs(twitter_data)\n",
    "        twitter_data_ = delete_hashtag_tweets_groups(twitter_data_)\n",
    "        twitter_data_ = delete_hashtag_eos(twitter_data_)\n",
    "        twitter_data_ = delete_url(twitter_data_)\n",
    "        twitter_data_ = delete_username_sos(twitter_data_)\n",
    "        twitter_data_ = delete_inline_username(twitter_data_)\n",
    "        twitter_data_ = delete_brackets(twitter_data_)\n",
    "        twitter_data_ = delete_emoji(twitter_data_)\n",
    "        twitter_data_ = delete_blank(twitter_data_)\n",
    "        data = delete_line_feed_code(twitter_data_)\n",
    "        num_rawdata = int(len(twitter_data)/3)\n",
    "        num_processed_data = int(len(data)/3)\n",
    "        yield_rate = num_processed_data/num_rawdata\n",
    "        print('The Number of Raw Data: '+str(num_rawdata))\n",
    "        print('The Number of Pre-processed Data: '+str(num_processed_data))\n",
    "        print('Yield Rate: '+str(yield_rate))\n",
    "        if(save):\n",
    "            save_file = open(save_name,'wb') \n",
    "            pickle.dump(data,save_file)\n",
    "            save_file.close\n",
    "        return None\n",
    "    except:\n",
    "        import traceback\n",
    "        print('pre-processing is failed')\n",
    "        traceback.print_exc()\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_triple/'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5229c38a8071>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"data_triple/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mfiles_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;31m###.ipython_checkpointを削除\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfiles_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_triple/'"
     ]
    }
   ],
   "source": [
    "path = \"data_triple/\"\n",
    "files = os.listdir(path)\n",
    "files_file = [f for f in files if os.path.isfile(os.path.join(path, f))]###.ipython_checkpointを削除\n",
    "print(len(files_file),files_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = []\n",
    "files_file=files_file#[:3]\n",
    "for ele in files_file:\n",
    "    data_lines = []\n",
    "    data = open(path+ele,'r',encoding='utf-8')\n",
    "    data_lines = data.readlines()\n",
    "    twitter_data.extend(data_lines)\n",
    "    data.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Number of Raw Data: 4958954\n",
      "The Number of Pre-processed Data: 4099090\n",
      "Yield Rate: 0.8266037555500616\n"
     ]
    }
   ],
   "source": [
    "pre_process(twitter_data,save=False,save_name='twitter_preprocessed1121.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['前まで兵長のバスマット使ってたの。 でも毎日毎日兵長のお顔がずぶ濡れで、踏み付けて…あたしドsじゃないのになーって思ってたけど、よーーーく考えたら、お股の真下から兵長覗いてんよね？！？！ どっちがドsなんやああああああああああ！！！！って思ってしまってから、玄関マットにした', 'わらうwwwwww', '笑うっしょ？wwwww 気付いた時には、あわわわわわってなってたwww ちょっと内股気味で立ったりしてたしww', 'フォロー許可されるのまだですかねぇ？←', '今したよおおおお˙꒳\\u200b˙)', 'あざまる', 'お久しぶりすぎてやべぇわ ', 'なぜオルタニキ使ったのか…', '久しぶり過ぎて？マークが魔神柱ってことを忘れてましたwww', 'こんばんは笑', 'あっ…お元気ですか…？', 'お元気です～', '俺もいないので そろそろやばいですwww', 'これは車仲間集めて 合コンでもするしか←したことない', 'するしかないですね！www したことないなら なおさらwww', 'かわいすぎ、、、、キジ猫ってだけで贔屓目です', 'キジ猫とは ってググッちゃいました', '猫の模様はたくさんありますからね〜️こんな本があるくらい猫の模様は多彩で魅力的です笑 ', 'オフ会までの時間潰し', 'オフ会??', 'ロア無銭ライブからの花火オフ会♪', 'ラーメン大好き♡ 辛いのも大好き♡なよティ子見参キリッ', 'お！ラーメン女子！！！', 'つ ', 'え、なにがあったの！？w,', 'あれだったw ぴーこっく流れてて セリフのとこできゃーって笑', 'あ〜！wなるほどwww', 'ぴーぴー最近見かけないよね… こーすけは良い人オーラが出てるw', '確かに見かけない\\\\/ ただふじに口悪いのが気に食わないひだ', '足マリオ好きやったんやけどなぁ… まぁ、仲がいいからこそ口が悪くなっちゃうんやでw ', 'はいはいは笑ったwwwwww', 'なんでですか!! いっぱい聞いてってもあさんが言うからです！', 'そうだねwww', '強化レイドって武器のだよねあれもカタヌキ手にはいるる？？', 'んーん、イベントのレイド会場で8時と10時に出るやつ！ 強いからちんじゃうかもなんだけど、参加賞がイネノミ500、カタヌキ100だからちんでもすぐ戻って参戦してってやると１回のレイドで3戦4戦できてσdｳﾏｳﾏ!!!', 'あー！あれか！ 0ダメかまして申し訳なさすぎて一回きりやってないんだなぁwww', '貢さん、こんにちは。 \\\\≡３', 'リサさん、こんにちは⁾⁾', 'ありがとうございます ', 'ぴょまえだれやねんって言われるかと 思ったけどセーフだった', '自発やり直しや！', '同じこと言われたんですけど() ', '彼女がキュート属性でないのなら一体何なのだ ', 'ブリュンヒルデ()', 'か わ い い 。 ', '囲いやめます', 'ちょまってうそやだやだやめてやめて', 'えへへ♡〜 ', 'それはヲタ卒見えてきた！', 'ゆうきくんはヲタク移籍だから 大丈夫だよ︎ 強制移籍させられるみたいよ笑', 'なんでやwww やめさせてくれーwww', 'あれ？ベルサイユ宮殿ですか？', '誰が絶対王政の象徴だ', 'ワロタwww', 'わしの嫁になるしか', 'プロポーズ来たwww', '脳内でウェディングベル鳴った？', '1つ後のツイートみて、安心しましたwww こういうのは無限に湧きますからねww', 'ほんとねwww 定期的に上がってきますよねwww', '釣りアカウント作って遊ぼうかな？と思うほどwww', '今日は、初めて、ライブにシークレットゲストとして、出演させていただきました！ みんなの声援、とても暖かくて、緊張したけどすごく楽しかったです！ 浴衣きたよ！ 本当にありがとうございました ', 'お疲れ様でした〜浴衣だったんですか！？いきたかったです...', '浴衣でした！！せっかくなら、浴衣配信しよかなぁ', 'ありがとうございます いや本当にそれわかりすぎて！というかご飯に牛乳あわせるの拷問じゃないですか？？私の術後のご飯はおにぎりと漬物とお味噌と牛乳でした！w', 'ですよね！なぜ牛乳をつける！！？？ってなります！残して、後で飲んでましたwwああ、おにぎりいいなぁ。脊髄麻酔で負担少ないんだから飯粒食わせろ！！！ってなってましたww', '脊椎麻酔だったんですね〜？？私は全身麻酔だったので、その違いですかね？？ とにかく牛乳はご飯に合わない上にお腹タプタプになるメニューはやめていただきたかったですwww痛いからトイレ行くのも大変だというのにw', 'やっと貰った〜 ', 'おーーー！おめでと！はやいですね！', 'ずっと脳筋してましたw とりあえずb上がったらセフィロスおやすみしようと思います', '恐れ多いです… レポってなんですか？僕大学生じゃないのでレポートとか書いたりしないです社畜なので', 'あ、あにょ。。ボンたろー失礼しますか？', 'ボンたろーさん失礼しますw!w!w! ', 'なかなか返ってこないけど私リアチン？ㅎ', '大丈夫、リアチンもっと返してない wwww ちゃんとしないと〜ㅠㅠㅠ', '私も元からlineマメに返せてないから 反省しとく…', '3周年の福袋ついでに課金石少し余ったので回したら鬼引きした ', 'だぁぁあああ北斎ちゃんなんでそっちなんだこっちにおいdくぁw背dｒｆｔｇｙふじこ', 'わいもエキストラで引いたお！ ', 'そらとも、まつりす、すこん部etcのフォロワーさんでfgoやってる方の中で優しい方がいればフレ登録していただけませんか…？ ', 'この通り、育成サボってるマンですがそんな雑魚でもよろしければお願い致しますmm ヘラクレス君を使ってあげて下さい ', 'ありが…3つ同じリプきてるよぉおおお！？ ', 'どういうこと？ﾌﾞﾌｫwww', '落ち着いてってことです笑 17時から貰えますよ！', 'え？w斜め上過ぎるwww 今日の？？', '急に言われだしたの〜', 'みるくちゃん！ギンギンなのwいかんつぼってご飯吹いたw', 'あかんwww ちゃんと食べてwww', '逆に何のコスで行くんですす？', 'なぜコスする前提なのですかねえ… やるならハイランダーとか、カッコいいのがいいですねー(๑•̀ㅁ•́ฅ✧←するとは言ってない', 'おや？夏コミに来ることは否定しないと言う事は夏コミ行くんですね！？何日目にいくんですか', 'あえて割りに行く？とかwww', 'それは何度もやったからー…', 'ほら、落ちるとちょっと無双出来たりするしwww ', 'ss9出来たんやで ', 'デッキを見せてください。', 'っ ', '2日来れないのか 4日まで我慢デェス なんとなくwwww', 'だからさっき棒読みでガンバッテネってエール送ったやんw 仕事次第やな〜早く終われば行けるーー物販だけ行くか？？ 旋フリとメルハー行ったから？www', 'あれ棒読みだったからロボット の絵文字だったのwww 仕事早く終わりますように 物販ーーーー‧✩͓̊ɞ₎₎✩ 違うもーーーんぷいっ', '/んぴｯ']\n",
      "12297270\n"
     ]
    }
   ],
   "source": [
    "with open('twitter_preprocessed1121.pickle', 'rb') as data_triple:\n",
    "    data = pickle.load(data_triple)\n",
    "print(type(data))\n",
    "print(data[:100])\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ありがとうございます!', 'これからよろしくお願いしますペコリ', 'こちらこそよろしくお願いします', 'いや意外と距離ある笑', '普通に遠い', 'え、だよね?wらら横で働いてたことあったからそんな近くだっけ!?ってw', 'ありがとうございます!そうなんですね!情報ありがとうございます️1発で飛ばすか最後まで残すとサインもらえるらしいので1発目は横行きますね笑', '頑張ってください!クラブに通い続けたエロオヤジが見つけた必勝法らしいのでw実際わたしはそれで小林由依ちゃんに勝てましたw', '笑いましたw私も頑張ります', 'ナイス!w', 'むしろワシのアイコンをみほの顔にするわw', 'wそれはうけるわw', 'ぜひとも黒子っちと赤司くん!いいですよね私は秀徳の高尾和成推しです️でも箱推しすごい分かりますw', '赤司くんはとくに映画からぐんっと来てますあ!秀徳いいですよね秀徳はみんな可愛くて箱推しです高尾スパダリ!ですよねw結局そうなってしまうのです', 'ペラペラな英語流石でしたよね️あと人格がひとつになったのも胸アツでした!ほんとに!家族みたいな秀徳ほんと好きですhsk!最終的に行き着くところそこですよねw', '小瀧!', 'はゐ!', '構え!', 'セーラームーン今こんな感じです。', '可愛い', 'あぁありがとう', '俺もほとんど見たゾ', 'さすがや', 'ありがとナス', '|・ω・｀)フムフムありがとうございます♪( \\'ω\\' و(و\"', 'いえいえ!モンスターは見た目で判断しろと習っているのでっ!', '間違いないですブフォw見た目大事ですよね♪( \\'ω\\' و(و\"', 'みんなが絶対に目に付く所に置いて来たよwこんな所置くとかエグいwとか言って喜んでたわ←は', 'さっすがーこのちゃんエグいって言いながら実はもう見てたりして本当は喜んでる️ブヒャヒャヒャ', '今は見てないw仕事中やからねっ。ﾟﾟ。仕事終わったら見るって言ってたwここのサロンのスタッフさん全員ヲタクやねんl社、j社、ケーポだから写真集も進めとくぅーって言ってたw', 'フォローありがとうございます!フォロバさせていただきます︎早速ですがなんとお呼びしましょう?', 'ありがとうございますなつめでいいですよ!', 'じゃあなつめって呼ぶね!まだお友達少ないから仲良くしてほしいな♡', 'ひぐらしは45rtされたら顔を晒してください。リア友から再度強制でまわってきたけど。45rtもいく訳がないのでツイートします。今日は引きこもりなのであたまボサボサのすっぴんだから', 'ひぐらしさん、おやすみなさい', 'おはようございます__ 3時過ぎててちょっとビックリしましたw', '去年の2月くらいかなぁまだ免許無い時', 'こんな時もあったんだね今は不正改造疑惑', 'ケツマンとちがってちゃんと車検対応ディーラー出入りおk仕様じゃ']\n",
      "\n",
      "['譲)画像参照 求)未所持の百合野さん 伊織さん 宜しくお願い申し上げます。 #執事歌劇団 https://t.co/au0ifxuv9t\\n', '更新致します。 ハートのついてるものはお譲り決まりました！ https://t.co/twpc8ewy0r\\n', '更新します https://t.co/nromgdndcr\\n', '@hourglassmee ありがとうございます！😊\\n', '@me03258 これからよろしくお願いします(❁ᴗ͈ˬᴗ͈)ﾍﾟｺﾘ🌷\\n', '@hourglassmee こちらこそよろしくお願いします( ´ ᵕ ` )\\n', '@princess__0123 いや意外と距離ある笑笑\\n', '@lisa6237 @princess__0123 普通に遠い\\n', '@kaimicki_523 @lisa6237 え、だよね？wwwらら横で働いてたことあったからそんな近くだっけ！？ってwww\\n', 'ねこです(怒)よろしくお願いします(怒) https://t.co/zwcfzjaypw\\n', '皆さんねこ好きですネ。ねこでした。\\n', 'ねこです。たくさんのいいねこ、rtありがとうございます。ねこですもこんなに喜んで…寝込んでます。ねこでした。 https://t.co/d9mvz3skiw\\n', '@shii054 ありがとうございます！ そうなんですね！情報ありがとうございます☺️1発で飛ばすか最後まで残すとサインもらえるらしいので1発目は横行きますね笑\\n', '@r_u__k_a_ 頑張ってください！ クラブに通い続けたエロオヤジが見つけた必勝法らしいのでw 実際わたしはそれで小林由依ちゃんに勝てましたw\\n', '@shii054 笑いましたwww 私も頑張ります😖\\n', '@yume_juju214 ナイス！www\\n', '@twice_9_momo むしろワシのアイコンをみほの顔にするわwww\\n', '@yume_juju214 wwwそれはうけるわw\\n', '@asaki_fafa ぜひとも😊💓 黒子っちと赤司くん！いいですよね〜💕私は秀徳の高尾和成推しです✌️でも箱推しすごい分かりますww\\n', '@7___ch 赤司くんはとくに映画からぐんっと来てます(笑) ああああ！秀徳いいですよね…秀徳はみんな可愛くて箱推しです…😭🙏🙏高尾スパダリ！ ですよねｗｗｗ結局そうなってしまうのです☺\\n', '@asaki_fafa ペラペラな英語流石でしたよね😂❤️あと人格がひとつになったのも胸アツでした……！ ほんとに…！！家族みたいな秀徳ほんと好きです😭😭hsk！！！ 最終的に行き着くところそこですよねwww\\n', '予定はなかったんだけど並んでなかったので『アートアクアリウム』 https://t.co/mux4yzgnwq\\n', 'アートアクアリウム② https://t.co/itklnadqsc\\n', 'アートアクアリウム③ https://t.co/cdodzanz5o\\n', '@heure_u_x 小瀧 ！！！\\n', '@__da_i_ki_xxx は ゐ ！！！\\n', '@heure_u_x 構え ！\\n', 'セーラームーン今こんな感じです。 https://t.co/qc96hekfuw\\n', '@doda_271905 可愛い…\\n', '@dooooooooodle53 あぁぁありがとう(´；ω；｀ )\\n', '@musaryu_634 俺もほとんど見たｿﾞ\\n', '@t_aehc さすがや...\\n', '@musaryu_634 ありがとナス🍆 https://t.co/hwbdkvmfrw\\n', '@8ejgmhsxrsokcue |･ω･｀)ﾌﾑﾌﾑ ありがとうございます♪( \\'ω\\' و(و \"\\n', '@taco_1218 いえいえ！ モンスターは見た目で判断しろと 習っているのでっ！\\n', '@8ejgmhsxrsokcue 間違いないです(´^ω^｀)ﾌﾞﾌｫwww 見た目大事ですよね♪( \\'ω\\' و(و \"\\n', '@erina0926anire6 みんなが絶対に目に付く所に置いて来たよwwwwww こんな所置くとかエグいwwwwwwwwwとか言って喜んでたわ😙💛←は\\n', '@kono1775 さっすがーこのちゃん🤩🤩😘🤩 エグいって言いながら〜実はもう見てたりして👀😍👀 本当は喜んでる⁉️(≧∇≦)ﾌﾞﾋｬﾋｬﾋｬ\\n', '@erina0926anire6 今は見てないwww仕事中やからねっ｡ﾟ(ﾟ＾ω＾°)ﾟ｡ 仕事終わったら見るって言ってたwww ここのサロンのスタッフさん全員ヲタクやねん🤣 l社、j社、ケーポ🤣 だから写真集も進めとくぅーーって言ってたwww\\n', '@_natsume_12 フォローありがとうございます ！ フォロバさせていただきます 😳❤︎ 早速ですがなんとお呼びしましょう ？\\n', '@tsumu_winter ありがとうございます(｡&gt;﹏&lt;｡) なつめでいいですよ！\\n', '@_natsume_12 じゃあなつめって呼ぶね ！ まだお友達少ないから仲良くしてほしいな 😖♡\\n', 'ひぐらしは45rtされたら顔を晒してください。 https://t.co/kpkyhjjhxd リア友から再度強制でまわってきたけど。45rtもいく訳がないのでツイートします。今日は引きこもりなのであたまボサボサのすっぴんだから… https://t.co/f42jzp1hlq\\n', '@tp_agp4 ひぐらしさん、おやすみなさい💤\\n', '@ryutv5 おはようございます_(-ω-`_)⌒)_ 3時過ぎててちょっとビックリしましたwww\\n', '@chinatsusister そう、猫の成長とてもはやい( ´･ω･`)\\n', '@curemura3rd ｡ﾟ(ﾟ´д｀ﾟ)ﾟ｡今も可愛いけどな\\n', '@chinatsusister (´-ω-)ｳﾑずっとかわいい 猫になりたい( ˙-˙ )\\n', '@defy4_105_hkr18 去年の2月くらいかなぁ まだ免許無い時\\n', '@iwacybr9 こんな時もあったんだね... 今は...不正改造疑惑...\\n', '@defy4_105_hkr18 ケツマンとちがってちゃんと車検対応ディーラー出入りおk仕様じゃ💢💢💢💢💢💢 https://t.co/4sbrh5kjs4\\n']\n"
     ]
    }
   ],
   "source": [
    "end = 51\n",
    "twitter_data_ = delete_self_reply_pairs(twitter_data[0:end])\n",
    "twitter_data_ = delete_hashtag_tweets_groups(twitter_data_)\n",
    "twitter_data_ = delete_hashtag_eos(twitter_data_)\n",
    "twitter_data_ = delete_url(twitter_data_)\n",
    "twitter_data_ = delete_username_sos(twitter_data_)\n",
    "twitter_data_ = delete_inline_username(twitter_data_)\n",
    "twitter_data_ = delete_brackets(twitter_data_)\n",
    "twitter_data_ = delete_emoji(twitter_data_)\n",
    "twitter_data_ = delete_same_char_sequence(twitter_data_)\n",
    "twitter_data_ = neolog_normalize(twitter_data_)\n",
    "twitter_data_ = delete_blank(twitter_data_)\n",
    "data = delete_line_feed_code(twitter_data_)\n",
    "print(data)\n",
    "print()\n",
    "print(twitter_data[0:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MeCab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = MeCab.Tagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "あぁ\t感動詞,*,*,*,*,*,あぁ,アァ,アー\n",
      "あぁ\n",
      "うんこ\t名詞,一般,*,*,*,*,うんこ,ウンコ,ウンコ\n",
      "うんこ\n",
      "が\t助詞,格助詞,一般,*,*,*,が,ガ,ガ\n",
      "が\n",
      "大好き\t名詞,形容動詞語幹,*,*,*,*,大好き,ダイスキ,ダイスキ\n",
      "大好き\n",
      "EOS\n",
      "eos\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mecab.parse(\"うんこが大好き\").split(\"\\n\")\n",
    "sentence = \"あぁうんこが大好き\"\n",
    "for m in mecab.parse(sentence).split(\"\\n\"): # 形態素解析で単語に分解する\n",
    "    print(m)\n",
    "    w = m.split(\"\\t\")[0].lower() # 単語\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AAA'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 'aaa'#'ﾍﾟｺﾘ'\n",
    "print(a)\n",
    "a.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ああああぁぁぁうんこが大好きだし、ももも好きwwｗｗwwｗｗ\n",
      "あぁうんこが大好きだし、ももも好きｗｗｗｗ\n"
     ]
    }
   ],
   "source": [
    "a = 'ああああぁぁぁうんこが大好きだし、ももも好きwwｗｗWWＷＷ'.lower()#'おいし〜〜〜〜い'\n",
    "print(a)\n",
    "a = re.sub(r'あ{3,}','あ',a)\n",
    "a = re.sub(r'ぁ{2,}','ぁ',a)\n",
    "a = re.sub(r'w{2,}','',a)\n",
    "print(a)\n",
    "a = neologdn.normalize(a,repeat=2)\n",
    "#print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xe3\\x81\\x8a'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter_data[0][27].encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ぃあいうえおいいいいい'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_text = 'ぃぃぃぃあいうえおいいいいい'\n",
    "re.sub(r'ぃ{2,}', 'ぃ', tweet_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37-mikami_saturn",
   "language": "python",
   "name": "py37-mikami_saturn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
